"""
B√ÄI T·∫¨P: T·∫†O H·ªÜ TH·ªêNG EMBEDDING V√Ä T√åM KI·∫æM THU·ªêC B·∫∞NG FAISS

M·ª•c ti√™u: X√¢y d·ª±ng m·ªôt class ƒë·ªÉ:
1. ƒê·ªçc d·ªØ li·ªáu thu·ªëc t·ª´ file JSON
2. K·∫øt h·ª£p c√°c thu·ªôc t√≠nh c·ªßa m·ªói lo·∫°i thu·ªëc th√†nh 1 ƒëo·∫°n text
3. T·∫°o embeddings b·∫±ng OpenAI
4. L∆∞u v√†o FAISS index ƒë·ªÉ t√¨m ki·∫øm

Ki·∫øn th·ª©c c·∫ßn c√≥:
- Python c∆° b·∫£n (class, list, dict, v√≤ng l·∫∑p)
- ƒê·ªçc/ghi file JSON
- S·ª≠ d·ª•ng th∆∞ vi·ªán pathlib ƒë·ªÉ x·ª≠ l√Ω ƒë∆∞·ªùng d·∫´n
"""

import json
from pathlib import Path
from typing import List, Dict
from langchain_openai import OpenAIEmbeddings
from langchain_google_genai import GoogleGenerativeAIEmbeddings  # ‚ú® Thay OpenAI
from langchain_community.vectorstores import FAISS
from langchain.docstore.document import Document
import pickle
import dotenv 
dotenv.load_dotenv()


# ========== B∆Ø·ªöC 2: T·∫†O CLASS DrugEmbedding ==========
class DrugEmbedding:
    """
    Class ch√≠nh ƒë·ªÉ x·ª≠ l√Ω embedding v√† t√¨m ki·∫øm thu·ªëc
    """
    
    def __init__(self, data_path: str = "./drugs-data-main/data"):
        """
        H√†m kh·ªüi t·∫°o - Ch·∫°y ƒë·∫ßu ti√™n khi t·∫°o object DrugEmbedding
        
        Args:
            data_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu thu·ªëc
        
        Nhi·ªám v·ª•:
        1. L∆∞u ƒë∆∞·ªùng d·∫´n d·ªØ li·ªáu
        2. T·∫°o ƒë∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c details (ch·ª©a c√°c file JSON thu·ªëc)
        3. Kh·ªüi t·∫°o OpenAIEmbeddings (c·∫ßn OPENAI_API_KEY trong bi·∫øn m√¥i tr∆∞·ªùng)
        4. Kh·ªüi t·∫°o c√°c bi·∫øn l∆∞u tr·ªØ: vector_store v√† drugs_data
        """

        self.data_path = Path(data_path)        
        self.details_path = self.data_path / "details"
        self.embeddings=GoogleGenerativeAIEmbeddings(
            model="models/text-embedding-004"  
        )
        self.vector_store = None  # S·∫Ω l∆∞u FAISS index
        self.drugs_data = []      # S·∫Ω l∆∞u danh s√°ch thu·ªëc ƒë√£ ƒë·ªçc
    
    
    def load_drug_data(self) -> List[Dict]:
        """
        ƒê·ªçc t·∫•t c·∫£ file JSON thu·ªëc t·ª´ th∆∞ m·ª•c details
        
        Returns:
            List[Dict]: Danh s√°ch c√°c dictionary, m·ªói dict ch·ª©a th√¥ng tin 1 lo·∫°i thu·ªëc
        
        Thu·∫≠t to√°n:
        1. T·∫°o list r·ªóng ƒë·ªÉ ch·ª©a d·ªØ li·ªáu thu·ªëc
        2. Ki·ªÉm tra xem th∆∞ m·ª•c details c√≥ t·ªìn t·∫°i kh√¥ng
        3. Duy·ªát qua t·∫•t c·∫£ th∆∞ m·ª•c con (danh m·ª•c thu·ªëc) trong details
        4. V·ªõi m·ªói danh m·ª•c, ƒë·ªçc t·∫•t c·∫£ file .json
        5. Load n·ªôi dung JSON v√† th√™m v√†o list
        6. Tr·∫£ v·ªÅ list ƒë√£ ƒë·ªçc
        """
        # TODO: T·ª± ho√†n thi·ªán h√†m n√†y
        # G·ª£i √Ω c√°c b∆∞·ªõc:
        
        # B∆∞·ªõc 1: T·∫°o list r·ªóng
        drugs = []
        for category_dir in self.details_path.iterdir():
            category_name=category_dir.name
            print(f"ƒêang x·ª≠ l√Ω: {category_name}")
            for json_file in category_dir.glob("*.json"):
                with open(json_file,'r',encoding='utf-8') as f:
                    drug_data=json.load(f)
                    drug_data['category']=category_name
                    drug_data['file_name']=json_file.stem
                    drugs.append(drug_data)
                    
        self.drugs_data=drugs
        return drugs

    
    
    def combine_drug_attributes(self, drug: Dict) -> str:
        """
        K·∫øt h·ª£p t·∫•t c·∫£ thu·ªôc t√≠nh c·ªßa 1 lo·∫°i thu·ªëc th√†nh 1 chu·ªói text
        
        Args:
            drug: Dictionary ch·ª©a th√¥ng tin thu·ªëc (ƒë·ªçc t·ª´ JSON)
        
        Returns:
            str: Chu·ªói text ƒë√£ k·∫øt h·ª£p t·∫•t c·∫£ thu·ªôc t√≠nh
        
        V√≠ d·ª• input:
        {
            "category": "C∆°-x∆∞∆°ng-kh·ªõp",
            "file_name": "thuoc-giam-dau",
            "describe": "Thu·ªëc gi·∫£m ƒëau...",
            "ingredient": "Paracetamol 500mg",
            ...
        }
        
        V√≠ d·ª• output:
        '''
        Danh m·ª•c:
        C∆°-x∆∞∆°ng-kh·ªõp
        
        T√™n file:
        thuoc-giam-dau
        
        M√¥ t·∫£:
        Thu·ªëc gi·∫£m ƒëau...
        
        Th√†nh ph·∫ßn:
        Paracetamol 500mg
        ...
        '''
        """

        fields = [
            ('Danh m·ª•c', drug.get('category', '')),
            ('T√™n thu·ªëc', drug.get('file_name', '')),
            ('M√¥ t·∫£', drug.get('describe', '')),
            ('Th√†nh ph·∫ßn', drug.get('ingredient', '')),
            ('C√¥ng d·ª•ng', drug.get('usage', '')),
            ('Li·ªÅu d√πng', drug.get('dosage', '')),
            ('T√°c d·ª•ng ph·ª•', drug.get('adverse_effect', '')),
            ('L∆∞u √Ω', drug.get('careful', '')),
            ('B·∫£o qu·∫£n', drug.get('preservation', ''))
        ]
        combined_text=""
        for field_name,field_data in fields:
            combined_text += f"\n{field_name}:\n{field_data}\n"
        combined_text=combined_text.strip()
        return combined_text

    
    def create_documents(self) -> List[Document]:
        """
        T·∫°o danh s√°ch Document t·ª´ d·ªØ li·ªáu thu·ªëc
        Document l√† ƒë·ªãnh d·∫°ng m√† LangChain y√™u c·∫ßu ƒë·ªÉ t·∫°o embeddings
        
        Returns:
            List[Document]: Danh s√°ch c√°c Document
        
        C·∫•u tr√∫c Document:
        - page_content: N·ªôi dung text (t·ª´ combine_drug_attributes)
        - metadata: Th√¥ng tin b·ªï sung (id, category, file_name, source)
        """

        if not self.drugs_data:
            self.load_drug_data()

        documents=[]
        for index,drug in enumerate(self.drugs_data):
            combined_text=self.combine_drug_attributes(drug)
            metadata={
                'id':index,
                'category':drug['category'],
                'file_name':drug['file_name'],
            }
            doc = Document(page_content=combined_text, metadata=metadata)
            documents.append(doc)
        return documents

    
    def create_embeddings_and_index(self, save_path: str = "./faiss_index",batch_size=10):
        """
        T·∫°o embeddings cho t·∫•t c·∫£ documents v√† l∆∞u v√†o FAISS index
        
        Args:
            save_path: ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u FAISS index
        
        Returns:
            FAISS vector store
        
        Quy tr√¨nh:
        1. T·∫°o documents t·ª´ d·ªØ li·ªáu thu·ªëc
        2. S·ª≠ d·ª•ng OpenAI ƒë·ªÉ t·∫°o embeddings cho m·ªói document
        3. FAISS s·∫Ω t·ª± ƒë·ªông t·∫°o index t·ª´ embeddings
        4. L∆∞u index v√†o disk
        """
        print("üìö ƒêang t·∫°o documents...")
        documents = self.create_documents()
        print(f"‚úÖ ƒê√£ t·∫°o {len(documents)} documents")
        print(f"üîÑ ƒêang t·∫°o embeddings (batch_size={batch_size})...")
        for i in range(0, len(documents), batch_size):
            batch = documents[i:i + batch_size]
            print(f"   Batch {i//batch_size + 1}/{(len(documents)-1)//batch_size + 1}: {len(batch)} documents")
        
            # T·∫°o FAISS index cho batch ƒë·∫ßu ti√™n
            if i == 0:
                self.vector_store = FAISS.from_documents(
                    documents=batch,
                    embedding=self.embeddings
                )
            else:
                # Merge batch ti·∫øp theo v√†o vector_store
                batch_store = FAISS.from_documents(
                    documents=batch,
                    embedding=self.embeddings
                )
                self.vector_store.merge_from(batch_store)
    
        print("‚úÖ ƒê√£ t·∫°o xong embeddings!")
        print("üíæ ƒêang l∆∞u index...")
        self.save_index(save_path)
        print(f"‚úÖ ƒê√£ l∆∞u index v√†o {save_path}")
    

        return self.vector_store
        

    
    def save_index(self, save_path: str = "./faiss_index"):
        """
        L∆∞u FAISS index v√† d·ªØ li·ªáu thu·ªëc v√†o disk
        
        Args:
            save_path: ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u
        """

        
        Path(save_path).mkdir(parents=True,exist_ok=True)
        self.vector_store.save_local(save_path)
        path=Path(save_path)/"drugs_data.pkl"
        with open(path,'wb') as f:
            pickle.dump(self.drugs_data,f)
            
    
    
    def load_index(self, load_path: str = "./faiss_index"):
        """
        Load FAISS index ƒë√£ l∆∞u t·ª´ disk
        
        Args:
            load_path: ƒê∆∞·ªùng d·∫´n ch·ª©a index
        """

        self.vector_store=FAISS.load_local(
            load_path,
            self.embeddings,
            allow_dangerous_deserialization=True
        )
        with open(Path(load_path) / "drugs_data.pkl", "rb") as f:
            self.drugs_data = pickle.load(f)
        
    
    
    def search(self, query: str, k: int = 5) -> List[Dict]:
        """
        T√¨m ki·∫øm thu·ªëc d·ª±a tr√™n c√¢u h·ªèi
        
        Args:
            query: C√¢u h·ªèi (VD: "thu·ªëc tr·ªã ƒëau ƒë·∫ßu")
            k: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ tr·∫£ v·ªÅ
        
        Returns:
            List c√°c k·∫øt qu·∫£ t√¨m ki·∫øm (c√≥ ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng)
        """

        result=self.vector_store.similarity_search_with_score(query,k=k)
        format_results=[]
        for doc,score in result:
            format_results.append({
                "content": doc.page_content,
                "metadata": doc.metadata,
                "score": score
            })
        return format_results


# ========== B∆Ø·ªöC 3: H√ÄM MAIN ƒê·ªÇ CH·∫†Y CH∆Ø∆†NG TR√åNH ==========
def main():
    """
    H√†m main - ƒëi·ªÉm b·∫Øt ƒë·∫ßu c·ªßa ch∆∞∆°ng tr√¨nh
    
    Quy tr√¨nh:
    1. Kh·ªüi t·∫°o DrugEmbedding
    2. T·∫°o embeddings v√† FAISS index
    3. Test t√¨m ki·∫øm
    """
    # TODO: T·ª± ho√†n thi·ªán
    # G·ª£i √Ω:
    
    # B∆∞·ªõc 1: T·∫°o object DrugEmbedding
    drug_embedding = DrugEmbedding(data_path="./drugs-data-main/data")
    
    # B∆∞·ªõc 2: T·∫°o embeddings v√† index
    drug_embedding.create_embeddings_and_index(save_path="./faiss_index")
    
    # B∆∞·ªõc 3: Test t√¨m ki·∫øm
    results = drug_embedding.search("thu·ªëc tr·ªã ƒëau x∆∞∆°ng kh·ªõp", k=3)
    for i, result in enumerate(results, 1):
        print(f"K·∫øt qu·∫£ {i}: {result['metadata']['file_name']}")
    
    


# Ch·∫°y ch∆∞∆°ng tr√¨nh
if __name__ == "__main__":
    main()

